{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec5e5b6",
   "metadata": {},
   "source": [
    "# Homework 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addfbb1e",
   "metadata": {},
   "source": [
    "## Code Explanation\n",
    "\n",
    "This solution loads the pretrained KMeans, TF–IDF vectorizer, and k-NN index, then for each query image it extracts SIFT descriptors, quantizes them into visual-word labels, builds a TF–IDF histogram, and retrieves the single nearest database cover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb51ee",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "1. Evaluate how accurately the system is able to find the books in the query images.\n",
    "    - From these six query examples, the system returns the exact same cover as its #1 hit in five out of six cases—an 83% top-1 accuracy—and retrieves the correct book somewhere in its top five every time (100 % top-5 accuracy). Overall, that indicates the bag-of-visual-words + TF–IDF + knn pipeline is reliably homing in on the right title almost immediately, with only very close stylistic look-alikes occasionally jumping ahead.\n",
    "\n",
    "2. What do you notice about the search results that are not the same book as the query image? Are these search results related to the search query in some way?\n",
    "    - When the system’s top pick isn’t the exact same cover, it consistently retrieves another title whose visual design closely mirrors the query—in color, composition, or illustration style—rather than matching by author or subject matter. For example, the “Are You My Mother?” query surfaces “Spot Says Goodnight” first, because both feature a lone cartoon animal on a flat pastel background with large, simple title text; likewise, the Pigeon books often pull one another (e.g. “Don’t Let the Pigeon Stay Up Late!” versus “The Pigeon Wants a Puppy!”) thanks to their identical hand-drawn pigeon typography. In every case, the false positives aren’t semantically related stories but rather the covers that look most visually similar under our bag-of-visual-words representation.\n",
    "\n",
    "3. The two images in extra-queries are of books not included in the database. Test what happens when you search for these books.\n",
    "    - Done\n",
    "\n",
    "4. Can you think of a way to automatically determine if the search was successful, or if the book being searched is not in the database?\n",
    "    - One way to to see if the cosine distance is above a certain threshold. If the distance is above the threshold, we can say that the book is not in the database. Another way is to check if the top-1 result is not in the database. Another better way is to make a model like a svm on the histograms of known covers and then use that model to classify the query image."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
